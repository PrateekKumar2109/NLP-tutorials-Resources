{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3CURpEQYNlICTCrJc+yNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrateekKumar2109/NLP-tutorials-Resources/blob/main/custom_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHR2t7Vz8UA_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "f7050ffe-c020-4b71-d417-9d2c8a4005df"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e2aef9ed0393>\"\u001b[0;36m, line \u001b[0;32m84\u001b[0m\n\u001b[0;31m    prompt=f\"You are an AI who performs one task based on the following objective: {objective}. Your task: {task}\\nResponse:\"t,\u001b[0m\n\u001b[0m                                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import cohere\n",
        "import faiss\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import deque\n",
        "from typing import Dict, List\n",
        "\n",
        "# Set API Keys\n",
        "OPENAI_API_KEY = \"\"\n",
        "YOUR_TABLE_NAME = \"test_table\"\n",
        "OBJECTIVE = \"Solve world hunger.\"\n",
        "YOUR_FIRST_TASK = \"Develop a task list.\"\n",
        "\n",
        "# Print OBJECTIVE\n",
        "print(\"\\033[96m\\033[1m\" + \"\\n*****OBJECTIVE*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "print(OBJECTIVE)\n",
        "\n",
        "# Configure OpenAI\n",
        "#openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Create Faiss index\n",
        "dimension = 1536\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "# Task list\n",
        "task_list = deque([])\n",
        "\n",
        "# Rest of your code remains unchanged\n",
        "\n",
        "def add_task(task: Dict):\n",
        "    task_list.append(task)\n",
        "\n",
        "def get_ada_embedding(text):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return co.embed(model='large',input=[text]).embeddings\n",
        "    #return openai.Embedding.create(input=[text], model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n",
        "\n",
        "def task_creation_agent(objective: str, result: Dict, task_description: str, task_list: List[str]):\n",
        "    prompt = f\"You are an task creation AI that uses the result of an execution agent to create new tasks with the following objective: {objective}, The last completed task has the result: {result}. This result was based on this task description: {task_description}. These are incomplete tasks: {', '.join(task_list)}. Based on the result, create new tasks to be completed by the AI system that do not overlap with incomplete tasks. Return the tasks as an array.\"\n",
        "    #response = openai.Completion.create(engine=\"text-davinci-003\",prompt=prompt,temperature=0.5,max_tokens=100,top_p=1,frequency_penalty=0,presence_penalty=0)\n",
        "    response = co.generate(\n",
        "    model='xlarge',\n",
        "    prompt=prompt,\n",
        "    return_likelihoods = 'NONE',\n",
        "    stop_sequences=['\"'],\n",
        "    max_tokens=100,\n",
        "    temperature=0.7,\n",
        "    )\n",
        "    new_tasks = response.choices[0].text.strip().split('\\n')\n",
        "    return [{\"task_name\": task_name} for task_name in new_tasks]\n",
        "\n",
        "def prioritization_agent(this_task_id:int):\n",
        "    global task_list\n",
        "    task_names = [t[\"task_name\"] for t in task_list]\n",
        "    next_task_id = int(this_task_id)+1\n",
        "    prompt = f\"\"\"You are an task prioritization AI tasked with cleaning the formatting of and reprioritizing the following tasks: {task_names}. Consider the ultimate objective of your team:{OBJECTIVE}. Do not remove any tasks. Return the result as a numbered list, like:\n",
        "    #. First task\n",
        "    #. Second task\n",
        "    Start the task list with number {next_task_id}.\"\"\"\n",
        "    response = co.generate(\n",
        "    model='xlarge',\n",
        "    prompt=prompt,\n",
        "    return_likelihoods = 'NONE',\n",
        "    stop_sequences=['\"'],\n",
        "    max_tokens=1000,\n",
        "    temperature=0.5,\n",
        "    )\n",
        "    new_tasks = response.choices[0].text.strip().split('\\n')\n",
        "    task_list = deque()\n",
        "    for task_string in new_tasks:\n",
        "        task_parts = task_string.strip().split(\".\", 1)\n",
        "        if len(task_parts) == 2:\n",
        "            task_id = task_parts[0].strip()\n",
        "            task_name = task_parts[1].strip()\n",
        "            task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
        "\n",
        "def execution_agent(objective:str,task: str) -> str:\n",
        "    #context = context_agent(index=\"quickstart\", query=\"my_search_query\", n=5)\n",
        "    context=context_agent(index=YOUR_TABLE_NAME, query=objective, n=5)\n",
        "    #print(\"\\n*******RELEVANT CONTEXT******\\n\")\n",
        "    #print(context)\n",
        "    response = co.generate(\n",
        "    model='xlarge',\n",
        "    prompt=f\"You are an AI who performs one task based on the following objective: {objective}. Your task: {task}\\nResponse:\"t,\n",
        "    return_likelihoods = 'NONE',\n",
        "    stop_sequences=['\"'],\n",
        "    max_tokens=2000,\n",
        "    temperature=0.7,\n",
        "    )\n",
        "    \n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "# Replace context_agent with the following\n",
        "def context_agent(query: str, index, n: int):\n",
        "    query_embedding = get_ada_embedding(query)\n",
        "    query_embedding = np.array(query_embedding).astype(\"float32\")\n",
        "    query_embedding = np.expand_dims(query_embedding, axis=0)\n",
        "    _, results = index.search(query_embedding, n)\n",
        "    \n",
        "    return [str(item) for item in results[0]]\n",
        "\n",
        "# Replace the following line in the execution_agent function\n",
        "#context=context_agent(index=YOUR_TABLE_NAME, query=objective, n=5)\n",
        "context = context_agent(index=index, query=objective, n=5)\n",
        "\n",
        "# Replace the following lines in the main loop\n",
        "# index.upsert([(result_id, get_ada_embedding(vector),{\"task\":task['task_name'],\"result\":result})])\n",
        "embedding = get_ada_embedding(vector)\n",
        "embedding = np.array(embedding).astype(\"float32\")\n",
        "index.add_with_ids(np.array([embedding]), np.array([result_id]))\n",
        "\n",
        "time.sleep(1)  # Sleep before checking the task list again\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import faiss\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import deque\n",
        "from typing import Dict, List\n",
        "\n",
        "# Set API Keys\n",
        "\n",
        "YOUR_TABLE_NAME = \"test_table\"\n",
        "OBJECTIVE = \"Create a summary of Industrial revolution.\"\n",
        "\n",
        "YOUR_FIRST_TASK = \"Develop a task list.\"\n",
        "\n",
        "# Print OBJECTIVE\n",
        "print(\"\\033[96m\\033[1m\" + \"\\n*****OBJECTIVE*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "print(OBJECTIVE)\n",
        "\n",
        "\n",
        "\n",
        "# Create Faiss index\n",
        "dimension = 4096\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "print(f\"Index dimension: {index.d}\")  # Add this line\n",
        "\n",
        "# Task list\n",
        "task_list = deque([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSpzW5fxEdXO",
        "outputId": "d80613aa-1f45-464b-ca7e-c8ba347a5b43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\u001b[1m\n",
            "*****OBJECTIVE*****\n",
            "\u001b[0m\u001b[0m\n",
            "Create a summary of Industrial revolution.\n",
            "Index dimension: 4096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = 'vGCEakgncpouo9Nz0rsJ0Bq7XRvwNgTCZMKSohlg'\n",
        "import cohere\n",
        "co = cohere.Client(api_key)"
      ],
      "metadata": {
        "id": "LtMwYNgFBYkx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_list = deque([])\n",
        "def add_task(task: Dict):\n",
        "    task_list.append(task)\n",
        "\n",
        "\n",
        "def get_ada_embedding(text):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    embeddings = co.embed(model='large', texts=[text]).embeddings\n",
        "    print(f\"Embedding length: {len(embeddings[0])}\")  # Change this line\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "def task_creation_agent(objective: str, result: Dict, task_description: str, task_list: List[str]):\n",
        "    prompt = f\"You are an task creation AI that uses the result of an execution agent to create new tasks with the following objective: {objective}, The last completed task has the result: {result}. This result was based on this task description: {task_description}. These are incomplete tasks: {', '.join(task_list)}. Based on the result, create new tasks to be completed by the AI system that do not overlap with incomplete tasks. Return the tasks as an array.\"\n",
        "    #response = openai.Completion.create(engine=\"text-davinci-003\",prompt=prompt,temperature=0.5,max_tokens=100,top_p=1,frequency_penalty=0,presence_penalty=0)\n",
        "    response = co.generate(\n",
        "    model='xlarge',\n",
        "    prompt=prompt,\n",
        "    return_likelihoods = 'NONE',\n",
        "    stop_sequences=['\"'],\n",
        "    max_tokens=100,\n",
        "    temperature=0.7,\n",
        "    )\n",
        "    new_tasks = response.choices[0].text.strip().split('\\n')\n",
        "    return [{\"task_name\": task_name} for task_name in new_tasks]\n",
        "\n",
        "def prioritization_agent(this_task_id:int):\n",
        "    global task_list\n",
        "    task_names = [t[\"task_name\"] for t in task_list]\n",
        "    next_task_id = int(this_task_id)+1\n",
        "    prompt = f\"\"\"You are an task prioritization AI tasked with cleaning the formatting of and reprioritizing the following tasks: {task_names}. Consider the ultimate objective of your team:{OBJECTIVE}. Do not remove any tasks. Return the result as a numbered list, like:\n",
        "    #. First task\n",
        "    #. Second task\n",
        "    Start the task list with number {next_task_id}.\"\"\"\n",
        "    response = co.generate(\n",
        "    model='xlarge',\n",
        "    prompt=prompt,\n",
        "    return_likelihoods = 'NONE',\n",
        "    stop_sequences=['\"'],\n",
        "    max_tokens=1000,\n",
        "    temperature=0.7,\n",
        "    )\n",
        "    new_tasks = response.choices[0].text.strip().split('\\n')\n",
        "    task_list = deque()\n",
        "    for task_string in new_tasks:\n",
        "        task_parts = task_string.strip().split(\".\", 1)\n",
        "        if len(task_parts) == 2:\n",
        "            task_id = task_parts[0].strip()\n",
        "            task_name = task_parts[1].strip()\n",
        "            task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
        "\n",
        "def execution_agent(objective:str,task: str) -> str:\n",
        "    #context = context_agent(index=\"quickstart\", query=\"my_search_query\", n=5)\n",
        "    context = context_agent(index=index, query=objective, n=5)\n",
        "    #print(\"\\n*******RELEVANT CONTEXT******\\n\")\n",
        "    #print(context)\n",
        "    response = co.generate(\n",
        "    model='xlarge',\n",
        "    prompt=f\"You are an AI who performs one task based on the following objective: {objective}. Your task: {task}\\nResponse:\",\n",
        "    return_likelihoods = 'NONE',\n",
        "    stop_sequences=['\"'],\n",
        "    max_tokens=2000,\n",
        "    temperature=0.5,\n",
        "    )\n",
        "    return response.data[0].text.strip()\n",
        "\n",
        "def context_agent(query: str, index, n: int):\n",
        "    query_embedding = get_ada_embedding(query)\n",
        "    query_embedding = np.array(query_embedding).reshape(1, -1).astype(\"float32\")\n",
        "    _, results = index.search(query_embedding, n)\n",
        "    \n",
        "    return [str(item) for item in results[0]]\n",
        "\n",
        "# Add the first task\n",
        "first_task = {\n",
        "    \"task_id\": 1,\n",
        "    \"task_name\": YOUR_FIRST_TASK\n",
        "}\n",
        "\n",
        "add_task(first_task)\n",
        "# Main loop\n",
        "task_id_counter = 1\n",
        "max_iterations = 5\n",
        "iteration = 0\n",
        "\n",
        "while iteration < max_iterations:\n",
        "    if task_list:\n",
        "        # Print the task list\n",
        "        print(\"\\033[95m\\033[1m\"+\"\\n*****TASK LIST*****\\n\"+\"\\033[0m\\033[0m\")\n",
        "        for t in task_list:\n",
        "            print(str(t['task_id'])+\": \"+t['task_name'])\n",
        "\n",
        "        # Step 1: Pull the first task\n",
        "        task = task_list.popleft()\n",
        "        print(\"\\033[92m\\033[1m\"+\"\\n*****NEXT TASK*****\\n\"+\"\\033[0m\\033[0m\")\n",
        "        print(str(task['task_id'])+\": \"+task['task_name'])\n",
        "\n",
        "        # Send to execution function to complete the task based on the context\n",
        "        result = execution_agent(OBJECTIVE,task[\"task_name\"])\n",
        "        this_task_id = int(task[\"task_id\"])\n",
        "        print(\"\\033[93m\\033[1m\"+\"\\n*****TASK RESULT*****\\n\"+\"\\033[0m\\033[0m\")\n",
        "        print(result)\n",
        "\n",
        "        # Step 2: Enrich result and store in Pinecone\n",
        "        enriched_result = {'data': result}  # This is where you should enrich the result if needed\n",
        "        result_id = f\"result_{task['task_id']}\"\n",
        "        vector = enriched_result['data']  # extract the actual result from the dictionary\n",
        "        embedding = get_ada_embedding(vector)\n",
        "        embedding = np.array(embedding).astype(\"float32\")\n",
        "        index.add_with_ids(embedding.reshape(1, -1), np.array([result_id]))\n",
        "\n",
        "        # Step 3: Create new tasks and reprioritize task list\n",
        "        new_tasks = task_creation_agent(OBJECTIVE,enriched_result, task[\"task_name\"], [t[\"task_name\"] for t in task_list])\n",
        "\n",
        "        for new_task in new_tasks:\n",
        "            task_id_counter += 1\n",
        "            new_task.update({\"task_id\": task_id_counter})\n",
        "            add_task(new_task)\n",
        "        prioritization_agent(this_task_id)\n",
        "\n",
        "    iteration += 1\n",
        "    time.sleep(1)  # Sleep before checking the task list again\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-PQdhJvX-2Ns",
        "outputId": "0d846334-ce4d-4a4d-e3a4-9927c19775e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[95m\u001b[1m\n",
            "*****TASK LIST*****\n",
            "\u001b[0m\u001b[0m\n",
            "1: Develop a task list.\n",
            "\u001b[92m\u001b[1m\n",
            "*****NEXT TASK*****\n",
            "\u001b[0m\u001b[0m\n",
            "1: Develop a task list.\n",
            "Embedding length: 4096\n",
            "\u001b[93m\u001b[1m\n",
            "*****TASK RESULT*****\n",
            "\u001b[0m\u001b[0m\n",
            "The Industrial Revolution began in Britain in the late 1700s and spread to the rest of Europe and the United States in the early 1800s. The first Industrial Revolution was characterized by the introduction of machinery and the factory system. The second Industrial Revolution began in the late 1800s and was characterized by the invention of the internal combustion engine, the assembly line, and other advances in technology. The third Industrial Revolution began in the late 1900s and is characterized by the use of computers and other information technologies.\n",
            "Response: The Industrial Revolution began in the late 1700s in Britain and spread to the rest of Europe and the United States in the early 1800s. The first Industrial Revolution was characterized by the introduction of machinery and the factory system. The second Industrial Revolution began in the late 1800s and was characterized by the invention of the internal combustion engine, the assembly line, and other advances in technology. The third Industrial Revolution began in the late 1900s and is characterized by the use of computers and other information technologies.\n",
            "Response: The Industrial Revolution began in Britain in the late 1700s and spread to the rest of Europe and the United States in the early 1800s. The first Industrial Revolution was characterized by the introduction of machinery and the factory system. The second Industrial Revolution began in the late 1800s and was characterized by the invention of the internal combustion engine, the assembly line, and other advances in technology. The third Industrial Revolution began in the late 1900s and is characterized by the use of computers and other information technologies.\n",
            "Response: The Industrial Revolution began in Britain in the late 1700s and spread to the rest of Europe and the United States in the early 1800s. The first Industrial Revolution was characterized by the introduction of machinery and the factory system. The second Industrial Revolution began in the late 1800s and was characterized by the invention of the internal combustion engine, the assembly line, and other advances in technology. The third Industrial Revolution began in the late 1900s and is characterized by the use of computers and other information technologies.\n",
            "Response: The Industrial Revolution began in Britain in the late 1700s and spread to the rest of Europe and the United States in the early 1800s. The first Industrial Revolution was characterized by the introduction of machinery and the factory system. The second Industrial Revolution began in the late 1800s and was characterized by the invention of the internal combustion engine, the assembly line, and other advances in technology. The third Industrial Revolution began in the late 1900s and is characterized by the use of computers and other information technologies.\n",
            "\n",
            "As you can see, there are many ways to respond to this question. The first two responses are very similar, but the third response is more detailed and provides more information.\n",
            "\n",
            "The first response provides a list of tasks that could be performed by an AI, but it does not specify what type of AI would perform these tasks. The second response provides more information about the Industrial Revolution, but it does not specify what type of AI would perform these tasks. The third response provides more detail about the Industrial Revolution and specifies that an AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail, but it does not specify what type of AI would perform these tasks. The third response is the longest and provides the most detail, but it does not specify what type of AI would perform these tasks.\n",
            "\n",
            "The first response is the shortest, but it does not provide enough information to answer the question. The second response is longer and provides more detail\n",
            "Embedding length: 4096\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-5316c18ab62d>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ada_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_with_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Step 3: Create new tasks and reprioritize task list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/faiss/class_wrappers.py\u001b[0m in \u001b[0;36mreplacement_add_with_ids\u001b[0;34m(self, x, ids)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'not same nb of vectors as ids'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_with_ids_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'result_1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "XxRMcNwi8b7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "wrqAhtFi8qHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WubQzHr81xG",
        "outputId": "cebd6d72-e5a1-4e25-d461-4077dc570c34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5F_Kycy9EEb",
        "outputId": "b71a242b-7f7b-4db9-897c-e54b3cf3efc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hgnmoKzD9F1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}